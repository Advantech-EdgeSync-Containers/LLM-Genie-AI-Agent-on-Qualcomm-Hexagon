
# Any other ollama or custom built model can be used here if needed
MODEL_NAME=llama3.2:1b
MODEL_CONFIG=/workspace/model/genie/htp-model-config-llama32-1b-gqa.json
MAX_PROMPT_GENERATION_TIMEOUT_IN_MIN=20

# --- Compose File ---
COMPOSE_FILE_PATH=./docker-compose.yml

# --- FASTAPI Settings ---
GENIE_LLM_PORT=8000
GENIE_LLM_HOST=0.0.0.0

# --- OPENWEBUI Settings ---
OPENWEBUI_PORT=3000
OPENAI_API_GENIE_BASE=http://0.0.0.0:8000

# Enables or disables chat title generation - default False
ENABLE_TITLE_GENERATION=False

# Enables or disables chat tag generation - default False
ENABLE_TAGS_GENERATION=False
